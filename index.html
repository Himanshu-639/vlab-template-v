<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="description" content="brief description" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Text Based Image Comparison</title>
  <link rel="icon" href="images/vlab-logo.png" type="image/x-icon" />
  <link rel="stylesheet" href="styles.css" />
  <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/base16/harmonic16-dark.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.8/clipboard.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
</head>

<body>
  <header class="header">
    <div class="logo-container">
      <div class="logo">
        <a href="https://www.vlab.andcollege.du.ac.in" rel="noopener" target="_blank">
          <img class="logo-img" src="images/logo.png" alt="VLab" />
        </a>
      </div>
      <h1 class="vlab">V-Lab@ANDC</h1>
    </div>

    <div class="menu-toggle" onclick="toggleMenu()">☰</div>
    <nav class="nav-menu" id="small-screen">
      <div class="close-btn" onclick="toggleMenu()">✖</div>
      <a href="https://www.vlab.andcollege.du.ac.in">Home</a>
      <a href="https://www.vlab.andcollege.du.ac.in#labs_section">Labs</a>
      <a href="https://www.vlab.andcollege.du.ac.in#team">Team</a>
      <a href="https://www.andcollege.du.ac.in">College Website</a>
    </nav>
  </header>

  <div class="yourvlabtitle">
    <h1>Text Based Image Comparison</h1>
  </div>

  <div class="pageview">
    <nav class="navigation">
      <button class="link" onclick="switchContent('aim')">
        <img class="icon" src="images/Aim_img.png" alt="Aim" />
        <span>Aim</span>
      </button>

      <button class="link" onclick="switchContent('theory')">
        <img class="icon" src="images/theory_img.png" alt="THEORY" />
        <span>Theory & Appli.</span>
      </button>

      <button class="link" onclick="switchContent('procedure')">
        <img class="icon" src="images/procedure_img.png" alt="PROCEDURE" />
        <span>Procedure</span>
      </button>

      <button class="link" onclick="switchContent('practice')">
        <img class="icon" src="images/practice_img.png" alt="PRACTICE" />
        <span>Practice</span>
      </button>

      <button class="link" onclick="switchContent('code')">
        <img class="icon" src="images/code_img.png" alt="CODES" />
        <span>Codes</span>
      </button>

      <button class="link" onclick="switchContent('result')">
        <img class="icon" src="images/result_img.png" alt="RESULT" />
        <span>Result</span>
      </button>

      <button class="link" onclick="switchContent('quiz')">
        <img class="icon" src="images/quiz_img.png" alt="QUIZ" />
        <span>Quiz</span>
      </button>

      <button class="link" onclick="switchContent('references')">
        <img class="icon" src="images/reference_img.png" alt="REFERENCE" />
        <span>References</span>
      </button>
      <button class="link" onclick="switchContent('tnt')">
        <img class="icon" src="images/tnt_img.png" alt="TEAM & TOOLS" />
        <span>Team & Tools</span>
      </button>
    </nav>

    <section class="main_practical">
      <!-- Aim -->
      <div class="container" id="aim">
        <div class="title">Aim</div>
        <div class="content">
          <p>The aim of this Virtual Lab is to demonstrate the process of extracting text from two images using OCR and
            comparing their content using Natural Language Processing techniques to determine their textual similarity
          </p>
        </div>
      </div>

      <!-- Theory & Applications -->
      <div class="container" id="theory">
        <div class="title">Theory & Applications</div>
        <div class="content">
          <p><br>
            This experiment demonstrates the integration of <b>Optical Character Recognition (OCR)</b> and
            <b>Natural Language Processing (NLP)</b> techniques to compute the textual similarity between
            two images. The process involves extracting text from image files, preprocessing the text,
            converting it into a weighted vector representation using <b>TF-IDF</b>, and finally measuring
            their similarity using <b>Cosine Similarity</b>.
          </p>

          <span>Key Concepts</span>
          <ul>
            <li><b>Optical Character Recognition (OCR)</b>
              <ul>
                <li><b>Definition:</b> OCR is a computer vision technique used to identify and extract
                  alphanumeric text from images using pattern recognition, convolutional models, or
                  deep learning techniques.</li>
                <li><b>Functionality:</b> It converts pixel-level image data into text by recognizing
                  character shapes and structures.</li>
                <li><b>In this project:</b> OCR is performed using the <b>OCR.space API</b>, which provides
                  high-accuracy text extraction, including support for some handwritten content.
                  While open-source libraries like <b>Tesseract</b> and <b>EasyOCR</b> can also be used
                  for this task, they are primarily optimized for printed or clearly structured text
                  and often underperform on real-world handwritten images. OCR.space gives better results
                  due to its training on diverse datasets.</li>
              </ul>
            </li>

            <li><b>Natural Language Processing (NLP)</b>
              <ul>
                <li><b>Definition:</b> NLP refers to the set of algorithms and processes that allow machines
                  to understand, interpret, and manipulate human language.</li>
                <li><b>Text Preprocessing:</b> A crucial stage that prepares raw text for similarity analysis.
                  It includes:
                  <ul>
                    <li><b>Lowercasing:</b> Converts all characters to lowercase to standardize the text.</li>
                    <li><b>Tokenization:</b> The process of breaking text into smaller units called tokens
                      (typically words). For example, "Text similarity project" → ["text", "similarity", "project"]</li>
                    <li><b>Stopword Removal:</b> Removes common words (like “is”, “the”, “of”) that carry little
                      semantic weight and don't contribute significantly to similarity measures.</li>
                    <li><b>Punctuation & Special Characters:</b> Stripped to avoid irrelevant variation
                      between texts.</li>
                  </ul>
                </li>
              </ul>
            </li>

            <li><b>TF-IDF (Term Frequency – Inverse Document Frequency)</b>
              <ul>
                <li><b>Purpose:</b> Converts textual data into numerical feature vectors that reflect term
                  importance in a document relative to a collection.</li>
                <li><b>Term Frequency (TF):</b> Measures how frequently a term appears in a document:
                  <br><code>TF(t) = (Number of times term t appears in a document) / (Total terms in document)</code>
                </li>
                <li><b>Inverse Document Frequency (IDF):</b> Reduces the weight of common terms by:
                  <br><code>IDF(t) = log(Total number of documents / Number of documents with term t)</code>
                </li>
                <li><b>TF-IDF Score:</b>
                  <br><code>TF-IDF(t) = TF(t) × IDF(t)</code>
                </li>
                <li>This representation allows us to model documents as vectors in a high-dimensional space
                  where each dimension corresponds to a term’s weight.</li>
              </ul>
            </li>

            <li><b>Cosine Similarity</b>
              <ul>
                <li><b>Definition:</b> Cosine similarity is a metric used to measure how similar two
                  vectors are, regardless of their magnitude.</li>
                <li><b>Mathematical Formula:</b>
                  <br><code>
                  Cosine Similarity = (A · B) / (||A|| × ||B||)
                  </code><br>
                  where A and B are the TF-IDF vectors of two documents.
                </li>
                <li><b>Interpretation:</b> The result ranges from 0 to 1:
                  <ul>
                    <li>1 → identical direction → highly similar</li>
                    <li>0 → orthogonal → completely dissimilar</li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>

          <span>Applications in Real World</span>
          <ol>
            <li>
              <b>Text-Based Image Comparison for Academic Integrity:</b>
              Educational platforms can use this system to compare scanned handwritten or printed assignments
              to detect content overlap using cosine similarity on preprocessed TF-IDF vectors — useful for
              plagiarism detection where traditional text matching tools fail.
            </li>
            <li>
              <b>Duplicate Document Detection in Digital Archives:</b>
              In large archives of scanned documents (legal files, forms, contracts), this technique can identify
              duplicate or near-duplicate text content across differently formatted or handwritten copies by
              comparing their TF-IDF representations.
            </li>
            <li>
              <b>Automated Metadata Tagging for Scanned Content:</b>
              When indexing a large number of scanned pages, NLP can be used to extract and summarize dominant
              terms using TF-IDF weights. These terms can be used to automatically generate tags or categories.
            </li>
            <li>
              <b>Evidence Matching in Digital Forensics:</b>
              Investigators can analyze and compare handwritten notes or printed letters using OCR and cosine similarity
              to find textual overlaps, especially when content is disguised or reformatted.
            </li>
            <li>
              <b>Document Clustering and Organization:</b>
              By generating TF-IDF vectors from scanned images, documents can be grouped into clusters
              (e.g., job applications, receipts, letters) based on textual similarity without manual sorting.
            </li>
          </ol>
        </div>
      </div>

      <!-- Procedure -->
      <div class="container" id="procedure">
        <div class="title">Procedure</div>
        <div class="content">
          <ol>
            <li><b>Upload Input Images</b>
              <ul>
                <li>Select two image files that contain textual content (e.g., typed documents, printed forms, or
                  handwritten notes).</li>
                <li>The interface provides two separate upload fields for Image 1 and Image 2.</li>
              </ul>
            </li>

            <li><b>Perform OCR on Uploaded Images</b>
              <ul>
                <li>Click the <i>"Extract Text"</i> button.</li>
                <li>Each image is sent to the OCR.space API.</li>
                <li>The API returns the extracted text for both images separately.</li>
                <li>The extracted text is displayed on the screen for verification.</li>
              </ul>
            </li>

            <li><b>Preprocess the Extracted Text</b>
              <ul>
                <li>Click the <i>"Preprocess Text"</i> button.</li>
                <li>The following preprocessing steps are applied to each extracted text:
                  <ul>
                    <li>Lowercasing</li>
                    <li>Removing punctuation and special characters</li>
                    <li>Tokenization (splitting text into words)</li>
                    <li>Stopword removal (removing common words like "the", "and", "is")</li>
                  </ul>
                </li>
                <li>The cleaned and tokenized text is then shown on the interface.</li>
              </ul>
            </li>

            <li><b>Vectorize the Text using TF-IDF</b>
              <ul>
                <li>The preprocessed texts from both images are converted into TF-IDF vectors.</li>
                <li>Each term is assigned a numerical weight based on its importance in the document and rarity across
                  documents.</li>
              </ul>
            </li>

            <li><b>Calculate Cosine Similarity</b>
              <ul>
                <li>Click the <i>"Calculate Similarity"</i> button.</li>
                <li>Cosine Similarity is calculated using the TF-IDF vectors:
                  <br>&nbsp;&nbsp;&nbsp; <code>Cosine Similarity = (A · B) / (||A|| × ||B||)</code>
                </li>
                <li>A similarity score between 0 and 1 is computed and displayed.</li>
                <li>The score indicates how similar the two images are based on their text content.</li>
              </ul>
            </li>

            <li><b>Interpret the Result</b>
              <ul>
                <li>A higher similarity score (close to 1) means the two texts are very similar or identical.</li>
                <li>A lower score (close to 0) means the texts are largely different.</li>
                <li>Students can upload different images to explore and analyze how text content affects similarity.
                </li>
              </ul>
            </li>
          </ol>

        </div>
      </div>

      <!-- Code -->
      <div class="container" id="code">
        <div class="title">Code</div>
        <p>Example programs</p>
        <div class="switch-container">
          <input class="togswt" type="radio" id="cppRadio" name="codeSwitch" checked />
          <label for="cppRadio">C++</label>

          <input class="togswt" type="radio" id="pythonRadio" name="codeSwitch" />
          <label for="pythonRadio">Python</label>
        </div>

        <div class="code-blocks">
          <div id="cppCode" class="code-block active">
            <div class="code-content">
              <pre><code class="language-cpp">// C++ Code Example</code></pre>
              <button class="copy-button">Copy</button>
            </div>
          </div>
          <div id="pythonCode" class="code-block">
            <div class="code-content">
              <pre><code class="language-python"># Python Code Example</code></pre>
              <button class="copy-button">Copy</button>
            </div>
          </div>
        </div>
      </div>

      <!-- Practice -->
      <div class="container" id="practice">
        <div class="title">Practice</div>
        <div class="content">
          <div class="contain">
            <div class="box" id="box1">
              <div class="upload-content" id="upload-content1">
                <div class="upload-icon">📤</div>
                <h3 id="label1">Upload Image 1</h3>
                <input type="file" id="image1" accept="image/*" style="display: none;">
              </div>
              <img id="preview1" style="display:none;">
            </div>
            <div class="box" id="box2">
              <div class="upload-content" id="upload-content2">
                <div class="upload-icon">📤</div>
                <h3 id="label2">Upload Image 2</h3>
                <input type="file" id="image2" accept="image/*" style="display: none;">
              </div>
              <img id="preview2" style="display:none;">
            </div>
          </div>

          <button onclick="extractText()">Extract Text</button>

          <div class="contain">
            <div class="output-box" id="text1">Extracted Text 1</div>
            <div class="output-box" id="text2">Extracted Text 2</div>
          </div>

          <button onclick="preprocessText()">Preprocess Text</button>

          <div class="contain">
            <div class="output-box" id="pre1">Preprocessed Text 1</div>
            <div class="output-box" id="pre2">Preprocessed Text 2</div>
          </div>

          <button onclick="calculateSimilarity()">Calculate Similarity</button>

          <div class="scorecard" id="similarityResult">Similarity: Not Calculated</div>
        </div>
      </div>

      <script>
        const imageInputs = [document.getElementById('image1'), document.getElementById('image2')];
        const previews = [document.getElementById('preview1'), document.getElementById('preview2')];
        const uploadContents = [document.getElementById('upload-content1'), document.getElementById('upload-content2')];
        const texts = [document.getElementById('text1'), document.getElementById('text2')];
        const preprocessed = [document.getElementById('pre1'), document.getElementById('pre2')];
        const base64Images = [null, null];
        const extractedTexts = ["", ""];

        imageInputs.forEach((input, index) => {
          const box = document.getElementById('box' + (index + 1));

          const handleImage = file => {
            const reader = new FileReader();
            reader.onload = function (e) {
              previews[index].src = e.target.result;
              previews[index].style.display = 'block';
              uploadContents[index].style.display = 'none';
              base64Images[index] = e.target.result.replace(/^data:image\/(png|jpg|jpeg);base64,/, '');
            };
            reader.readAsDataURL(file);
          };

          input.addEventListener('change', function () {
            if (this.files[0]) {
              handleImage(this.files[0]);
            }
          });

          ['dragenter', 'dragover'].forEach(eventName => {
            box.addEventListener(eventName, e => {
              e.preventDefault();
              box.classList.add('dragover');
            });
          });

          ['dragleave', 'drop'].forEach(eventName => {
            box.addEventListener(eventName, e => {
              e.preventDefault();
              box.classList.remove('dragover');
            });
          });

          box.addEventListener('drop', e => {
            const file = e.dataTransfer.files[0];
            if (file && file.type.startsWith('image/')) {
              handleImage(file);
            }
          });

          box.addEventListener('click', () => {
            input.value = ''; // clear previous file to avoid double trigger
            input.click();
          });
        });

        async function extractText() {
          const apiKey = 'K88181478588957';
          for (let i = 0; i < 2; i++) {
            if (!base64Images[i]) {
              texts[i].innerText = 'No image selected';
              continue;
            }
            texts[i].innerText = 'Extracting...';
            const formData = new FormData();
            formData.append('base64Image', 'data:image/jpeg;base64,' + base64Images[i]);
            formData.append('language', 'eng');
            formData.append('apikey', apiKey);
            formData.append('OCREngine', 2);
            try {
              const response = await fetch('https://api.ocr.space/parse/image', {
                method: 'POST',
                body: formData
              });
              const result = await response.json();
              const parsedText = result.ParsedResults?.[0]?.ParsedText || "No text found.";
              extractedTexts[i] = parsedText;
              texts[i].innerText = parsedText;
            } catch (error) {
              texts[i].innerText = 'Error during OCR';
            }
          }
        }

        function preprocessText() {
          for (let i = 0; i < 2; i++) {
            let text = extractedTexts[i].toLowerCase();
            text = text.replace(/[→V]/g, '').trim();
            const tokens = text.split(/\s+/);
            const stopwords = new Set(["i", "me", "my", "myself", "we", "our", "ours", "ourselves", "you", "your", "yours", "yourself", "yourselves",
              "he", "him", "his", "himself", "she", "her", "hers", "herself", "it", "its", "itself", "they", "them", "their",
              "theirs", "themselves", "what", "which", "who", "whom", "this", "that", "these", "those", "am", "is", "are", "was",
              "were", "be", "been", "being", "have", "has", "had", "having", "do", "does", "did", "doing", "a", "an", "the", "and",
              "but", "if", "or", "because", "as", "until", "while", "of", "at", "by", "for", "with", "about", "against", "between",
              "into", "through", "during", "before", "after", "above", "below", "to", "from", "up", "down", "in", "out", "on", "off",
              "over", "under", "again", "further", "then", "once", "here", "there", "when", "where", "why", "how", "all", "any",
              "both", "each", "few", "more", "most", "other", "some", "such", "no", "nor", "not", "only", "own", "same", "so",
              "than", "too", "very", "s", "t", "can", "will", "just", "don", "should", "now"]);
            const punctuations = new Set(["!", "\"", "#", "$", "%", "&", "'", "(", ")", "*", "+", ",", "-", ".", "/", ":", ";", "<", "=", ">", "?", "@", "[", "\\", "]", "^", "_", "`", "{", "|", "}", "~"]);
            const filtered = tokens.filter(token => !stopwords.has(token) && !punctuations.has(token));
            preprocessed[i].innerText = filtered.join(' ');
          }
        }

        function calculateSimilarity() {
          const docs = [preprocessed[0].innerText, preprocessed[1].innerText];
          const tokenizedDocs = docs.map(doc => doc.split(/\s+/));
          const allWords = Array.from(new Set(tokenizedDocs.flat()));

          const tfidfVectors = tokenizedDocs.map(words => {
            return allWords.map(word => {
              const tf = words.filter(w => w === word).length / words.length;

              // Compute correct DF (word occurrence per document)
              const df = tokenizedDocs.reduce((acc, docWords) => acc + (docWords.includes(word) ? 1 : 0), 0);

              // Smoothed IDF as used by scikit-learn
              const idf = Math.log((1 + tokenizedDocs.length) / (1 + df)) + 1;

              return tf * idf;
            });
          });

          const dotProduct = tfidfVectors[0].reduce((sum, val, i) => sum + val * tfidfVectors[1][i], 0);
          const magnitudeA = Math.sqrt(tfidfVectors[0].reduce((sum, val) => sum + val * val, 0));
          const magnitudeB = Math.sqrt(tfidfVectors[1].reduce((sum, val) => sum + val * val, 0));
          let similarity = dotProduct / (magnitudeA * magnitudeB);

          if (isNaN(similarity)) similarity = 0;

          document.getElementById('similarityResult').innerText = `Similarity: ${Math.round(similarity * 100)}%`;
        }
      </script>


      <!-- Results -->
      <div class="container" id="result">
        <div class="title">Result</div>
        <div class="content">
          <p><br>
            After completing all stages of the experiment—text extraction, preprocessing, vectorization, and similarity
            computation—the system generates a final similarity score that quantifies the textual resemblance between
            the two uploaded images.
          </p>

          <p>
            The result reflects how closely the extracted texts from both images match in terms of vocabulary and
            contextual meaning. This evaluation is purely based on textual content, independent of image properties such
            as resolution, color, or layout.
          </p><br>

          <ol>
            <li><b>Text Extraction:</b> Text is extracted from both images using OCR.space API. This API supports
              printed and partially handwritten text, improving accuracy over traditional OCR libraries in real-world
              scenarios.</li>

            <li><b>Text Preprocessing:</b> The extracted raw text is cleaned and normalized by applying NLP techniques
              like lowercasing, tokenization, stopword removal, and punctuation stripping. This step ensures consistency
              and removes irrelevant noise.</li>

            <li><b>Vector Representation (TF-IDF):</b> The processed text is converted into TF-IDF vectors, representing
              the importance of each word within the text and across both documents.</li>

            <li><b>Similarity Score (Cosine Similarity):</b> Finally, cosine similarity is computed between the two
              TF-IDF vectors. The resulting value lies between 0 and 1:
              <ul>
                <li><b>1:</b> Identical or near-identical text</li>
                <li><b>0:</b> Completely unrelated text</li>
                <li><b>Intermediate values:</b> Partially similar content</li>
              </ul>
            </li>
          </ol>

          <p>
            <b>Example Output:</b> If Image 1 contains “Artificial Intelligence is transforming the world” and Image 2
            contains “AI is changing the world”, the system might return a similarity score around <code>0.74</code>,
            reflecting significant overlap in meaning despite lexical differences.
          </p>

          <p>
            This similarity score provides a quantitative basis for comparing image-based documents and can be
            interpreted in various domains such as academic document analysis, automated review systems, and legal
            document matching.
          </p>
        </div>
      </div>

      <!-- Quiz -->
      <div class="container" id="quiz">
        <div class="title">Quiz</div>
        <p id="question"></p>
        <div id="choices" class="choices"></div>
        <button id="save-btn" class="save-button">Save</button>
        <button id="next-btn" class="next-button" style="display: none">
          Next
        </button>
        <button id="retake-btn" style="display: none">Retake Quiz</button>
        <div id="quiz-report" style="display: none"></div>
        <!-- Section to display quiz report -->
      </div>

      <!-- References -->
      <div class="container" id="references">
        <div class="title">References</div>
        <div class="content">
          <ul class="ref-list">
            <li>
              <span> refernce 1 </span>
            </li>
            <li>
              <span> refernce 2 </span>
            </li>
          </ul>
        </div>
      </div>

      <!-- Team & Tools -->
      <div class="container" id="tnt">
        <div class="title">Team & Tools</div>
        <div class="content">
          <h3>Students</h3>
          <ul class="ref-list">
            <li>
              <a href="https://www.linkedin.com/in/kriti-misra-b6014a29b" rel="noopener" target="_blank"><span>Kriti
                  Misra, BSc (Hons) Computer Science (2024-25)</span></a>
            </li>
            <li>
              <a href="https://www.linkedin.com/in/639himanshuyadav/" rel="noopener" target="_blank"><span>Himanshu
                  Yadav, BSc (Hons) Computer Science (2024-25)</span></a>
            </li>
          </ul>
          <h3>Mentors</h3>
          <ul class="ref-list">
            <li><span>Prof. Sharanjit Kaur, Department of Computer Science</span></li>
          </ul>
          <h3>Tools Used</h3>
          <ul class="tools-list">
            <li>
              <span>OCR.space API - for text extraction </span>
            </li>
            <li>
              <span>NLTK (Natural Language Toolkit) library - for text preprocessing </span>
            </li>
            <li>
              <span>TfidfVectorizer, cosine_similarity - for calculating similarity </span>
            </li>
            <li>
              <span>Vanilla HTML, CSS, JS - for creating the web page</span>
            </li>
            <li>
              <span>Flask - for backend </span>
            </li>
          </ul>
        </div>
      </div>
    </section>
  </div>
  <script>
    hljs.highlightAll();
    function toggleMenu() {
      const menu = document.querySelector(".nav-menu");
      menu.classList.toggle("show");
    }
  </script>
  <script src="script.js"></script>
</body>

</html>